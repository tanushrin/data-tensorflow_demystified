{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap about the fundamentals of Deep Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìÜ What's on the agenda for this recap?\n",
    "\n",
    "- ***Intro***: How to read the docs\n",
    "- ***Part 1Ô∏è‚É£***: Tensorflow de-mystified (üë®üèª‚Äçüè´ Teacher-led)\n",
    "- ***Part 2Ô∏è‚É£***: Tensorflow vs Numpy? (üë®üèª‚Äçüè´ Teacher-led)\n",
    "- ***Part 3Ô∏è‚É£***: Forest Fires Challenge (üë©‚Äçüéì Student-led)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro: How to read the docs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ [Tensorflow.org](https://www.tensorflow.org/overview) provides you with two main pages to refer to:\n",
    "- [Tutorial](https://www.tensorflow.org/tutorials)\n",
    "- [Guide](https://www.tensorflow.org/guide)\n",
    "- ***These should be your go-to pages***. You can even run `Colab-Notebooks` of these tutorials\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "‚úÖ TensorFlow [API docs](https://www.tensorflow.org/api_docs/python/tf/) contains only essential elements and advanced notions\n",
    "- It pops up in Google Search in priority\n",
    "- [Sometimes](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential), it can give you references to related Tutorials or Guides\n",
    "- ***Use it as THE single source of truth***\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "‚ùå [Keras.io](https://keras.io/about/) is somewhat redundant with the TensorFlow documentation\n",
    "- It contains nice tutorials and examples but...\n",
    "- ...use it only you don't find what you need on `Tensorflow.Keras`'s website\n",
    "- ***Don't use it for the docs***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1Ô∏è‚É£ - Tensorflow demystified \n",
    "_(üßëüèª‚Äçüè´ Teacher-led)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Goal: Using Tensorflow, create a dummy dataset and fit a dummy model with it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Tensors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìö [Online Guide](https://www.tensorflow.org/guide/tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's OK to import everything for notebook based experimentation!\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensors are wrappers around numpy objects\n",
    "\n",
    "X = tf.constant([[1., 1., 1.],\n",
    "                 [1., 1., 1.],\n",
    "                 [1., 1., 1.]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.ones((3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X.numpy()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensors have a shape\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensors can be initialized from Numpy objects\n",
    "tf.constant(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# They can be manipulated with syntax that is similar to Numpy\n",
    "tf.add(X,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversely, Numpy also accept Tensor elements!\n",
    "np.add(X,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a custom MSE loss function using Tensors\n",
    "\n",
    "def loss(y_true, y_pred):\n",
    "    err = y_true - y_pred\n",
    "    return tf.reduce_mean(tf.square(err))\n",
    "\n",
    "y_true = tf.ones((10,3))\n",
    "y_pred = tf.ones((10,3)) + 0.1 * tf.random.normal((10,3))\n",
    "\n",
    "loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Tensors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sparse Tensors**\n",
    "<img src=\"https://wagon-public-datasets.s3.amazonaws.com/data-science-images/DL/sparse_tensors.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_tensor = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2]],\n",
    "                                       values=[1, 2],\n",
    "                                       dense_shape=[3, 4])\n",
    "sparse_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ragged Tensors**\n",
    "<img src=\"https://wagon-public-datasets.s3.amazonaws.com/data-science-images/DL/ragged_tensors.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ragged_list = [\n",
    "    [0, 1, 2, 3],\n",
    "    [4, 5],\n",
    "    [6, 7, 8],\n",
    "    [9]]\n",
    "\n",
    "ragged_tensor = tf.ragged.constant(ragged_list)\n",
    "ragged_tensor.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Build a neural network with `Sequential API`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Let's generate 10 random observations `X` of 3 features each, and a unidimensional target `y` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generate 100 observations of with 10 features for each of them\n",
    "X = tf.random.uniform((100,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And create our dummy target as simply the mean of each observation\n",
    "y = tf.reduce_mean(X, axis=1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Let's build a simple dense model that \"works\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usual syntax\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(30, input_dim=10, activation='relu'))\n",
    "#model.add(layers.Dense(30, input_shape=(10,), activation='relu'))\n",
    "model.add(layers.Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalent\n",
    "model = Sequential([\n",
    "    layers.Dense(30, input_shape=(10, ), activation='relu'),\n",
    "    layers.Dense(1),\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we don't specify input_dim?\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(30, activation='relu'))\n",
    "model.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model.summary()\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One can still access all the layers individually\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And call the layer with a \"tensor\" as input\n",
    "x1 = model.layers[0](X)\n",
    "\n",
    "# x1 is our activation from layer 1, with random (initial) weights\n",
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x2 is our output\n",
    "x2 = model.layers[1](x1)\n",
    "x2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Keras Input layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will often encounter this in the docs:\n",
    "```python\n",
    "keras.Input(shape=(10,))\n",
    "```\n",
    "Instead of passing 100 **real** observations to your layers, simply pass a `keras.Input` of `None` observations of similar shape (10,).  \n",
    "\n",
    "It is used for computation optimization purposes (memory pre-allocation and network graphs for parallelization) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(10,))\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0](inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.layers[0](inputs) # Input layer\n",
    "x = layers.Dense(30, activation='relu')(inputs) # First layer output\n",
    "x = layers.Dense(20, activation='relu')(x) # Second layer output\n",
    "x = layers.Dense(10, activation='relu')(x) # Third layer output\n",
    "outputs = layers.Dense(1)(x)               # Final layer output\n",
    "\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras allows you to build a model from an input and output layer\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è This way of building models is called Keras [Functional API](https://www.tensorflow.org/guide/keras/functional)\n",
    "- as opposed to [Sequential API](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential): `model.add(...)`\n",
    "- It is mandatory for complex (non-sequential) architecture...\n",
    "- Used everywhere in the docs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2Ô∏è‚É£ - Tensorflow vs. Numpy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gSXzA9ixKUIx"
   },
   "source": [
    "### Difference between an array and a tensor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTaUg3UiKUIx"
   },
   "source": [
    "üëâ The important differences between NumPy arrays and tf.Tensors are:\n",
    "\n",
    "1. Tensors are immutable\n",
    "2. Tensors can be backed by accelerator memory (like GPU, TPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAraXPusKUIx"
   },
   "source": [
    "**Immutable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zqkg4cZNKUIx",
    "outputId": "a090bacb-107f-4987-80d5-f8b0e77ad3ca"
   },
   "outputs": [],
   "source": [
    "# an array element can be reassigned\n",
    "\n",
    "array = np.array([1,1,1])\n",
    "\n",
    "array[1] = 2\n",
    "\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "id": "vIUsnSFiKUIy",
    "outputId": "c13c94fd-fc15-427a-be7c-b605a44714ef"
   },
   "outputs": [],
   "source": [
    "# a tensor element can't be reassigned\n",
    "\n",
    "tensor = tf.constant([1., 1., 1.])\n",
    "\n",
    "tensor[1] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YXWhjq5HKUIy"
   },
   "source": [
    "**Backed by accelerator memory**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HL2wNQaKUIy"
   },
   "source": [
    "Tensors are backed by accelerator memory (like GPU, TPU). You can manually select the processor on which to perform your tensor operations.\n",
    "\n",
    "‚è©‚è©‚è© Check out the [documentation](https://www.tensorflow.org/guide/gpu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FsmmanvtKUIy",
    "outputId": "c2634ebb-d44c-4fd5-d82d-241282327d0a"
   },
   "outputs": [],
   "source": [
    "# Check CPU's available\n",
    "print(\"Num CPUs Available: \", len(tf.config.list_physical_devices('CPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-OPsEJq6KUIy",
    "outputId": "1f003495-b877-490e-cbd1-1cf2e2757d94"
   },
   "outputs": [],
   "source": [
    "# Check GPU's available\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OlxRtN2FKUIz"
   },
   "source": [
    "It is unliklely that your computer will have a GPU... Guess who offers free GPU usage? Google! \n",
    "\n",
    "üëâ **Let's switch to Google Colab to continue the recap and compare the processing times.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "viFY6VHhKUIz",
    "outputId": "0c73d688-4953-4619-d8ff-f3fad9c4b609"
   },
   "outputs": [],
   "source": [
    "# If you've set up Colab correctly, you should have a GPU avaiable.\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gbo9XVjNKUIz"
   },
   "outputs": [],
   "source": [
    "# Matrix multiplication function performing operation and returning us the time.\n",
    "import time\n",
    "\n",
    "def time_matmul(types,x):\n",
    "\n",
    "    start = time.time() \n",
    "\n",
    "    if types=='numpy':\n",
    "        np.matmul(x,x)\n",
    "\n",
    "    else:\n",
    "        tf.matmul(x,x)\n",
    "\n",
    "    diff = time.time() - start\n",
    "\n",
    "    return diff*1000\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá Run this cell twice (the first time it runs, tensorflow compilation for GPU takes a bit of time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lKrfs0uoKUIz",
    "outputId": "ee475c1d-5f9b-42da-af61-f16b33d3d3f7"
   },
   "outputs": [],
   "source": [
    "shape_dim = []\n",
    "num_time = []\n",
    "cpu_tf_time = []\n",
    "gpu_tf_time = []\n",
    "\n",
    "for shape in range(500,2001,100):\n",
    "\n",
    "    print(f\"Multiplication of shape [{shape},{shape}]\")\n",
    "\n",
    "  # Start with shape 500,500 to 2000,2000 with an increase of 100\n",
    "    shape_dim.append(shape)\n",
    "\n",
    "  # Numpy multiplication\n",
    "    x_np = np.random.uniform(size=[shape,shape])\n",
    "    num_time.append(time_matmul('numpy',x_np))\n",
    "  \n",
    "  #Tensor in CPU\n",
    "    with tf.device(\"CPU:0\"):\n",
    "        x = tf.random.uniform([shape, shape])\n",
    "        cpu_tf_time.append(time_matmul('cpu',x))\n",
    "        \n",
    "  #Tensor in GPU multiplication\n",
    "    with tf.device(\"GPU:0\"): #Or GPU:1 for the 2nd GPU, GPU:2 for the 3rd etc.\n",
    "        x = tf.random.uniform([shape, shape])\n",
    "        gpu_tf_time.append(time_matmul('gpu',x))\n",
    "\n",
    "print(\"Done multiplying!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "id": "t5Q604iCKUIz",
    "outputId": "d53b098d-f6a6-40c7-f510-fcb511bc585f"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(shape_dim, num_time, label=\"Numpy Array\")\n",
    "plt.plot(shape_dim, cpu_tf_time, label=\"Tensor in CPU\")\n",
    "plt.plot(shape_dim, gpu_tf_time, label=\"Tensor in GPU\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"Shape of the Matrix\")\n",
    "plt.ylabel(\"Time in milliseconds\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "goWQaDN0KUI0"
   },
   "source": [
    "üëâ **Check out our [tutorial](https://kitt.lewagon.com/knowledge/tutorials/data_google_colab) on how to set up Google Colab, you'll be using it in the coming days**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3Ô∏è‚É£ (optional) - Forest Fires Challenge \n",
    "(üë©‚ÄçüéìStudent-led)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Data\n",
    "\n",
    "`tensorflow_dataset` provides many `Datasets` that can be found <a href=\"https://www.tensorflow.org/datasets/catalog/overview\">here</a>\n",
    "\n",
    "Let's load the **`forest_fires`** dataset. The target is area damaged by fire (more details here https://www.tensorflow.org/datasets/catalog/forest_fires)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area, features = tfds.as_numpy(tfds.load(\n",
    "    'forest_fires',\n",
    "    split='train',\n",
    "    batch_size=-1,\n",
    "    as_supervised=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(features).values\n",
    "y = area\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "y = area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Declare the general architecture of your model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Import Keras and declare a Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Add a Dense layer with 50 neurons and the `relu` activation function. Do not forget to specify your `input_dim` for the first layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Add a second fully connected layer, with 20 neurons and the `relu` activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Add a last layer that suits your regression task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Check the number of parameters of your model.\n",
    "\n",
    "Re-count them manually to make sure you understood the numbers of parameters involved in each layer of your Dense Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Define how your model is trained\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Compile the model with the `adam` `optimizer` and the `mse` `loss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùìRun the model on this random data; don't forget to select a number of `epochs` and a `batch_size`. Store the returned result in `history`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Plot the model convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Write an entire model with its compilation within an `init_model` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are advised to systematically rebuild a model (with an init function) before fitting some data in order to re-initialize the model's parameters.\n",
    "\n",
    "The model you just wrote is suited for regression tasks.\n",
    "\n",
    "What if we want to perform a binary classification task?\n",
    "\n",
    "‚ùì Write another `init_model_2` function in which you will change:\n",
    "* the last layer of the architecture \n",
    "* and the compilation method\n",
    "\n",
    "used in a binary class classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Write a last function to define a model for a classification problem with 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
